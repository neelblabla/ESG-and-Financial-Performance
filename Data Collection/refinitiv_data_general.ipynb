{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"RD_LIB_CONFIG_PATH\"] = \"../Configuration\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import refinitiv.data as rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd.open_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_companies = pd.read_csv('Refinitiv_ESG_Universe.csv', delimiter=';')\n",
    "\n",
    "df_companies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_companies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example, also works with ISIN instead of BASF Ticker\n",
    "df = rd.get_data(\n",
    "    universe=[\"BASFn.DE\", \"IBM.N\"],\n",
    "    fields=[\"TR.HeadquartersCountry\", \"TR.HeadquartersRegion\", \"TR.NAICSNationalIndustry\", \"TR.NAICSIndustryGroup\", \n",
    "            \"TR.NAICSSector\", \"TR.GICSSubIndustry\", \"TR.GICSIndustry\", \"TR.ICBIndustry\", \"TR.ICBSector\", \"TR.GICSIndustryGroup\", \"TR.SICIndustryGroup\"\n",
    "            \"TR.GICSSector\", \"TR.SICIndustry\", \"TR.TRBCIndustry\", \"TR.TRBCIndustryGroup\", \"TR.TRBCBusinessSector\", \"TR.TRBCEconomicSector\",\n",
    "            \"TR.TSE33SectorNameMain\", \"TR.NAICSSubsector\"]\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stuff that doesn't change with time (Sector/Industry/Country/Region)\n",
    "# testing the loop\n",
    "test_frame = df_companies.iloc[:15, :]\n",
    "\n",
    "# loop to collect data for all available companies, stored in a dictionary with a df for each isin\n",
    "comp_data_dict = {}\n",
    "\n",
    "for isin in test_frame[\"ISIN\"]:\n",
    "    df = rd.get_data(\n",
    "        universe=isin,\n",
    "        fields=[\"TR.HeadquartersCountry\", \"TR.HeadquartersRegion\", \"TR.NAICSNationalIndustry\", \"TR.NAICSIndustryGroup\", \n",
    "            \"TR.NAICSSector\", \"TR.GICSSubIndustry\", \"TR.GICSIndustry\", \"TR.ICBIndustry\", \"TR.ICBSector\", \"TR.GICSIndustryGroup\", \"TR.SICIndustryGroup\"\n",
    "            \"TR.GICSSector\", \"TR.SICIndustry\", \"TR.TRBCIndustry\", \"TR.TRBCIndustryGroup\", \"TR.TRBCBusinessSector\", \"TR.TRBCEconomicSector\",\n",
    "            \"TR.TSE33SectorNameMain\", \"TR.NAICSSubsector\"]\n",
    "    )\n",
    "\n",
    "    comp_data_dict[isin] = df\n",
    "\n",
    "comp_dfs = []\n",
    "for key, df in comp_data_dict.items():\n",
    "    df['key'] = key  # Add a new column containing the key\n",
    "    comp_dfs.append(df)\n",
    "\n",
    "# Concatenate the dataframes into a single one\n",
    "comp_info_df_test = pd.concat(comp_dfs)\n",
    "\n",
    "# save the new dataframe\n",
    "comp_info_df_test.to_csv(\"comp_info_df_test.csv\")\n",
    "\n",
    "comp_info_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Stuff that doesn't change with time (Sector/Industry/Country/Region)\n",
    "\n",
    "# loop to collect data for all available companies, stored in a dictionary with a df for each isin\n",
    "comp_data_dict = {}\n",
    "\n",
    "for isin in df_companies[\"ISIN\"]:\n",
    "    \n",
    "    df = rd.get_data(\n",
    "        universe=isin,\n",
    "        fields=[\"TR.HeadquartersCountry\", \"TR.HeadquartersRegion\", \"TR.NAICSNationalIndustry\", \"TR.NAICSIndustryGroup\", \n",
    "            \"TR.NAICSSector\", \"TR.GICSSubIndustry\", \"TR.GICSIndustry\", \"TR.ICBIndustry\", \"TR.ICBSector\", \"TR.GICSIndustryGroup\", \"TR.SICIndustryGroup\"\n",
    "            \"TR.GICSSector\", \"TR.SICIndustry\", \"TR.TRBCIndustry\", \"TR.TRBCIndustryGroup\", \"TR.TRBCBusinessSector\", \"TR.TRBCEconomicSector\",\n",
    "            \"TR.TSE33SectorNameMain\", \"TR.NAICSSubsector\"]\n",
    "    )\n",
    "\n",
    "    comp_data_dict[isin] = df\n",
    "\n",
    "comp_dfs = []\n",
    "for key, df in comp_data_dict.items():\n",
    "    df['key'] = key  # Add a new column containing the key\n",
    "    comp_dfs.append(df)\n",
    "\n",
    "# Concatenate the dataframes into a single one\n",
    "comp_info_df = pd.concat(comp_dfs)\n",
    "\n",
    "# save the new dataframe\n",
    "comp_info_df.to_csv(\"comp_info_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the loop\n",
    "test_frame = df_companies.iloc[:15, :]\n",
    "\n",
    "# loop to collect data for all available companies, stored in a dictionary with a df for each isin\n",
    "financials_data_dict = {}\n",
    "\n",
    "for isin in test_frame[\"ISIN\"]:\n",
    "\n",
    "    df = rd.get_history(\n",
    "        universe=isin,\n",
    "        fields=[\"TR.RevenueMean\", \"TR.EarningsMean\", \"TR.F.EmpAvg\", \"TR.EPSMean\", \"TR.ROAMean\", \"TR.ROEMean\",\n",
    "        \"TR.Volume\", \"TR.CompanyMarketCap\", \"TR.FCFMean\", \"TR.WACC\", \"TR.EBITDAMean\", \"TR.OrganicSalesGrowthMean\"],\n",
    "        interval=\"1Y\",\n",
    "        start=\"2000-01-01\",\n",
    "        end=\"2023-01-01\",\n",
    "    )\n",
    "    \n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df = df.groupby(df.index.year).first()\n",
    "\n",
    "    financials_data_dict[isin] = df\n",
    "\n",
    "# Assume `dfs_dict` is the dictionary of dataframes\n",
    "dfs = []\n",
    "for key, df in financials_data_dict.items():\n",
    "    df['key'] = key  # Add a new column containing the key\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate the dataframes into a single one\n",
    "result = pd.concat(dfs)\n",
    "\n",
    "result.to_csv('comp_financials_test.csv')\n",
    "\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop to collect data for all available companies, stored in a dictionary with a df for each isin\n",
    "financials_data_dict = {}\n",
    "\n",
    "for isin in df_companies[\"ISIN\"]:\n",
    "\n",
    "    df = rd.get_history(\n",
    "        universe=isin,\n",
    "        fields=[\"TR.RevenueMean\", \"TR.EarningsMean\", \"TR.F.EmpAvg\", \"TR.EPSMean\", \"TR.ROAMean\", \"TR.ROEMean\",\n",
    "        \"TR.Volume\", \"TR.CompanyMarketCap\", \"TR.FCFMean\", \"TR.WACC\", \"TR.EBITDAMean\", \"TR.OrganicSalesGrowthMean\"],\n",
    "        interval=\"1Y\",\n",
    "        start=\"2000-01-01\",\n",
    "        end=\"2023-01-01\",\n",
    "    )\n",
    "    \n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df = df.groupby(df.index.year).first()\n",
    "\n",
    "    financials_data_dict[isin] = df\n",
    "\n",
    "# Assume `dfs_dict` is the dictionary of dataframes\n",
    "dfs = []\n",
    "for key, df in financials_data_dict.items():\n",
    "    df['key'] = key  # Add a new column containing the key\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate the dataframes into a single one\n",
    "result = pd.concat(dfs)\n",
    "\n",
    "result.to_csv('comp_financials.csv')\n",
    "\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stuff that changes with time (Revenue/Earnings/Employees/ROA/ROE/Free Cash Flow)\n",
    "# importing the dataframe with the relevant years\n",
    "#ESG_TR_df = pd.read_csv(\"tr_esg_df_cleaned.csv\")\n",
    "#\n",
    "#test_frame = ESG_TR_df.iloc[:30, :]\n",
    "#\n",
    "## loop to collect data for all available companies, stored in a dictionary with a df for each isin\n",
    "#comp_financials_data_dict = {}\n",
    "#\n",
    "#for year, isin in zip(test_frame[\"Year\"], test_frame[\"key\"]):\n",
    "#\n",
    "#    df = rd.get_history(\n",
    "#        universe=isin,\n",
    "#        fields=[\"TR.RevenueMean\", \"TR.EarningsMean\", \"TR.F.EmpAvg\", \"TR.EPSMean\", \"TR.ROAMean\", \"TR.ROEMean\",\n",
    "#        \"TR.Volume\", \"TR.CompanyMarketCap\", \"TR.FCFMean\", \"TR.WACC\", \"TR.EBITDAMean\", \"TR.OrganicSalesGrowthMean\"],\n",
    "#        interval=\"1Y\",\n",
    "#        start=str(year) + \"-01-01\",\n",
    "#        end=str(year + 1) + \"-01-01\",\n",
    "#    )\n",
    "#    \n",
    "#    df.index = pd.to_datetime(df.index)\n",
    "#    df = df.groupby(df.index.year).first()\n",
    "#\n",
    "#    dict_key = isin + str(year)\n",
    "#    comp_financials_data_dict[dict_key] = df\n",
    "#\n",
    "## Assume `dfs_dict` is the dictionary of dataframes\n",
    "#dfs = []\n",
    "#for key, df in comp_financials_data_dict.items():\n",
    "#    df['key'] = key  # Add a new column containing the key\n",
    "#    dfs.append(df)\n",
    "#\n",
    "## Concatenate the dataframes into a single one\n",
    "#comp_financials_test = pd.concat(dfs)\n",
    "#\n",
    "## save the new dataframe\n",
    "#comp_financials_test.to_csv('comp_financials_test.csv')\n",
    "#\n",
    "#comp_financials_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stuff that changes with time (Revenue/Earnings/Employees/ROA/ROE/Free Cash Flow)\n",
    "# importing the dataframe with the relevant years\n",
    "#ESG_TR_df = pd.read_csv(\"tr_esg_df_cleaned.csv\")\n",
    "#\n",
    "#test_frame = ESG_TR_df.iloc[:30, :]\n",
    "#\n",
    "## loop to collect data for all available companies, stored in a dictionary with a df for each isin\n",
    "#comp_financials_data_dict = {}\n",
    "#\n",
    "#def financials_collection(year, isin):\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#    df = rd.get_history(\n",
    "#        universe=isin,\n",
    "#        fields=[\"TR.Revenue\", \"TR.Earnings\", \"TR.F.EmpAvg\", \"TR.EPSMean\", \"TR.ROAMean\", \"TR.ROEMean\",\n",
    "#        \"TR.Volume\", \"TR.CompanyMarketCap\", \"TR.FCFMean\", \"TR.WACC\", \"TR.EBITDAMean\", \"TR.OrganicSalesGrowthMean\"],\n",
    "#        interval=\"1Y\",\n",
    "#        start=str(year) + \"-01-01\",\n",
    "#        end=str(year + 1) + \"-01-01\",\n",
    "#    )\n",
    "#    \n",
    "#    df.index = pd.to_datetime(df.index)\n",
    "#    df = df.groupby(df.index.year).first()\n",
    "#\n",
    "#    dict_key = isin + str(year)\n",
    "#\n",
    "#    comp_financials_data_dict[isin] = df\n",
    "#\n",
    "## Assume `dfs_dict` is the dictionary of dataframes\n",
    "#dfs = []\n",
    "#for key, df in comp_financials_data_dict.items():\n",
    "#    df['key'] = key  # Add a new column containing the key\n",
    "#    dfs.append(df)\n",
    "#\n",
    "## Concatenate the dataframes into a single one\n",
    "#comp_financials_test = pd.concat(dfs)\n",
    "#\n",
    "## save the new dataframe\n",
    "#comp_financials_test.to_csv('comp_financials_test.csv')\n",
    "#\n",
    "#comp_financials_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd.close_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "092fd3b47a62a288d64e0d56cb1d943a7dfc85b85fdb59434f57bdf2cec50c7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
